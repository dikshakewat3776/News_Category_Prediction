{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "News_Category_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf1W9vkKfErX",
        "colab_type": "text"
      },
      "source": [
        "# Text classification: News Category Prediction\n",
        "\n",
        "### [Hackathon Link](https://www.machinehack.com/course/predict-the-news-category-hackathon/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy-2XlrAfErY",
        "colab_type": "text"
      },
      "source": [
        "### Problem Statement with information about dataset\n",
        "Use Natural Language Processing to predict which genre or category a piece of news will fall in to from the story.\n",
        "\n",
        "Size of training set: 7,628 records\n",
        "Size of test set: 2,748 records\n",
        "\n",
        "FEATURES:\n",
        "\n",
        "STORY:  A part of the main content of the article to be published as a piece of news.\n",
        "SECTION: The genre/category the STORY falls in.\n",
        "\n",
        "There are four distinct sections where each story may fall in to. The Sections are labelled as follows :\n",
        "\n",
        "Politics: 0  \n",
        "Technology: 1  \n",
        "Entertainment: 2  \n",
        "Business: 3  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLYOZ28HfEra",
        "colab_type": "text"
      },
      "source": [
        "### Libraries import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5kIFx8rfErb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Remove warning in console\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# default libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#NLP specific libraries\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "\n",
        "#Accuracy metrics \n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#NLP libraries\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#Importing TfidfTransformer from sklearn\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "#Download the following modules once\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('wordnet')\n",
        "\n",
        "#Model libraries \n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuLtQVVyfErh",
        "colab_type": "text"
      },
      "source": [
        "### Import Data\n",
        "#### Download: [MachineHack Site](https://www.machinehack.com/wp-content/uploads/2019/07/Participants_Data_News_category-20190729T063600Z-001.zip)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZCPQEtnfErh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_train_df = pd.read_excel('./sample_data/Data_Train.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_30MWlrzfErl",
        "colab_type": "text"
      },
      "source": [
        "### Explore DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSQL9wyyfErl",
        "colab_type": "code",
        "colab": {},
        "outputId": "33d82fca-f41b-4ef2-9481-55bd150d4ce5"
      },
      "source": [
        "input_train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STORY</th>\n",
              "      <th>SECTION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>But the most painful was the huge reversal in ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How formidable is the opposition alliance amon...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Most Asian currencies were trading lower today...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you want to answer any question, click on ‘...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In global markets, gold prices edged up today ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               STORY  SECTION\n",
              "0  But the most painful was the huge reversal in ...        3\n",
              "1  How formidable is the opposition alliance amon...        0\n",
              "2  Most Asian currencies were trading lower today...        3\n",
              "3  If you want to answer any question, click on ‘...        1\n",
              "4  In global markets, gold prices edged up today ...        3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKQKZoBWfErp",
        "colab_type": "code",
        "colab": {},
        "outputId": "e2f4cc42-170a-4050-d228-9652cb52ff81"
      },
      "source": [
        "input_train_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7628 entries, 0 to 7627\n",
            "Data columns (total 2 columns):\n",
            "STORY      7628 non-null object\n",
            "SECTION    7628 non-null int64\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 119.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6dhU8E4fErs",
        "colab_type": "code",
        "colab": {},
        "outputId": "6e37694e-761f-421a-bba2-010d60a845ec"
      },
      "source": [
        "#Printing the shape of the dataset\n",
        "print(input_train_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7628, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utV9BC0TfErv",
        "colab_type": "code",
        "colab": {},
        "outputId": "5f719b80-8607-4862-9f78-cb38926579f1"
      },
      "source": [
        "#Printing the group by description of each category\n",
        "input_train_df.groupby(\"SECTION\").describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">STORY</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SECTION</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1686</td>\n",
              "      <td>1673</td>\n",
              "      <td>This story has been published from a wire agen...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2772</td>\n",
              "      <td>2731</td>\n",
              "      <td>This story has been published from a wire agen...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1924</td>\n",
              "      <td>1914</td>\n",
              "      <td>We will leave no stone unturned to make the au...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1246</td>\n",
              "      <td>1233</td>\n",
              "      <td>This story has been published from a wire agen...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        STORY                                                               \n",
              "        count unique                                                top freq\n",
              "SECTION                                                                     \n",
              "0        1686   1673  This story has been published from a wire agen...    4\n",
              "1        2772   2731  This story has been published from a wire agen...   13\n",
              "2        1924   1914  We will leave no stone unturned to make the au...    3\n",
              "3        1246   1233  This story has been published from a wire agen...   11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FesPNOmEfEry",
        "colab_type": "code",
        "colab": {},
        "outputId": "00d18cfe-943c-49ff-8b7a-ef40db68b149"
      },
      "source": [
        "#Check for null values\n",
        "input_train_df.isnull().values.any()\n",
        "input_train_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "STORY      0\n",
              "SECTION    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro-8d501fEr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removing duplicates to avoid overfitting\n",
        "input_train_df.drop_duplicates(inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "551zgtbjfEr3",
        "colab_type": "text"
      },
      "source": [
        "### EDA\n",
        "Code resources:      \n",
        "[Kaggle notebook on eda](https://www.kaggle.com/amokrane/eda-and-text-classification-with-scikit-learn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbA3e7t6fEr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Distribution plot of target column\n",
        "# ax, fig = plt.subplots(figsize=(10, 7))\n",
        "# sections_class = input_train_df[\"SECTION\"].value_counts()\n",
        "# sections_class.plot(kind= 'bar')\n",
        "# plt.title('Bar chart of news categories')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpYxWtCTfEr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Percentage distribution of target column categories:-\")\n",
        "# (input_train_df.groupby('SECTION').size()/input_train_df['SECTION'].count())*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY8PwERefEr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Divide target column into individual categories\n",
        "# politics = input_train_df[input_train_df[\"SECTION\"] == 0]\n",
        "# technology = input_train_df[input_train_df[\"SECTION\"] == 1]\n",
        "# entertainment = input_train_df[input_train_df[\"SECTION\"] == 2]\n",
        "# business = input_train_df[input_train_df[\"SECTION\"] == 3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtymTBG2fEr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get length of news stories for each category\n",
        "# politics[\"news_length\"] = politics.STORY.apply(lambda x: len(x))\n",
        "# technology[\"news_length\"] = technology.STORY.apply(lambda x: len(x))\n",
        "# entertainment[\"news_length\"] = entertainment.STORY.apply(lambda x: len(x))\n",
        "# business[\"news_length\"] = business.STORY.apply(lambda x: len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MabVV8GFfEsC",
        "colab_type": "text"
      },
      "source": [
        "**Distribution plot of target column categories**    \n",
        "More info on dist plot: [TowardsDataScience](https://towardsdatascience.com/histograms-and-density-plots-in-python-f6bda88f5ac0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1_4nFUBfEsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fig = plt.figure(figsize=(11.7,8.27))\n",
        "# sns.distplot(politics.news_length, hist=True, label=\"politics\")\n",
        "# sns.distplot(technology.news_length, hist=True, label=\"technology\")\n",
        "# sns.distplot(entertainment.news_length, hist=True, label=\"entertainment\")\n",
        "# sns.distplot(business.news_length, hist=False, label=\"business\")\n",
        "# plt.ylabel('Density of news story words')\n",
        "# plt.xlabel('New Story length')\n",
        "# fig.legend()\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWskfDjQfEsF",
        "colab_type": "text"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "**1)Text cleaning**    \n",
        "Cleaning of special characters, downcasing, punctuation signs. possessive pronouns and stop words removal and lemmatization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdpsGf-nfEsG",
        "colab_type": "text"
      },
      "source": [
        "**1.1Remove Punctutation**   \n",
        "Punctuation signs and special characters won't have any predicting power, so we'll just get rid of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "furkQ8OYfEsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_punctuations = string.punctuation + '‘’,:”][],' \n",
        "\n",
        "#Method to remove punctuation marks from the data\n",
        "def punc_remover(raw_text):\n",
        "    no_punct = \"\".join([i for i in raw_text if i not in all_punctuations])\n",
        "    return no_punct\n",
        "\n",
        "#Method to remove stopwords from the data\n",
        "def stopword_remover(no_punc_text):\n",
        "    words = no_punc_text.split()\n",
        "    no_stp_words = \" \".join([i for i in words if i not in stopwords.words('english')])\n",
        "    return no_stp_words\n",
        "\n",
        "#Method to lemmatize the words in the data\n",
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "def lem(words):\n",
        "    return \" \".join([lemmer.lemmatize(word,'v') for word in words.split()])\n",
        "\n",
        "#Method to perform a complete cleaning\n",
        "def text_cleaner(raw):\n",
        "    cleaned_text = stopword_remover(punc_remover(raw))\n",
        "    return lem(cleaned_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckMfpeGqfEsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Applying the cleaner method to the entire data\n",
        "input_train_df['CLEAN_STORY'] = input_train_df['STORY'].apply(text_cleaner)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWSD57B7fEsK",
        "colab_type": "code",
        "colab": {},
        "outputId": "b2a0491d-5022-40c5-9309-6e9453d84ae0"
      },
      "source": [
        "#Checking the new dataset\n",
        "print(input_train_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                               STORY  SECTION  \\\n",
            "0  But the most painful was the huge reversal in ...        3   \n",
            "1  How formidable is the opposition alliance amon...        0   \n",
            "2  Most Asian currencies were trading lower today...        3   \n",
            "3  If you want to answer any question, click on ‘...        1   \n",
            "4  In global markets, gold prices edged up today ...        3   \n",
            "\n",
            "                                         CLEAN_STORY  \n",
            "0  But painful huge reversal fee income unheard a...  \n",
            "1  How formidable opposition alliance among Congr...  \n",
            "2  Most Asian currencies trade lower today South ...  \n",
            "3  If want answer question click Answer After cli...  \n",
            "4  In global market gold price edge today disappo...  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnU5lAC1fEsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Exporting file to pickle to save time in processing data\n",
        "input_train_df.to_pickle('./sample_data/Pickles/input_train_df.pickle')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxq5AqhdfEsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_train_df = pd.read_pickle('./sample_data/Pickles/input_train_df.pickle')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13EiUzYafEsQ",
        "colab_type": "text"
      },
      "source": [
        "**2)Count Vectors and TF-IDF Vectors**    \n",
        "Create count vectors and TF-IDF vectors for feeding data into model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhkLMBRHfEsR",
        "colab_type": "text"
      },
      "source": [
        "**2.1 Create bag-of-words model using CountVectoriser**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iepuDcSwfEsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a bag-of-words dictionary of words from the data\n",
        "bow_dictionary = CountVectorizer().fit(input_train_df['CLEAN_STORY'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzK3NhQhfEsU",
        "colab_type": "code",
        "colab": {},
        "outputId": "63822005-31bf-4077-d30d-d3d0646a4d9c"
      },
      "source": [
        "#Total number of words in the bow_dictionary\n",
        "len(bow_dictionary.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvUSjG5gfEsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using the bow_dictionary to create count vectors for the cleaned data.\n",
        "bow = bow_dictionary.transform(input_train_df['CLEAN_STORY'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5aQgA1dfEsY",
        "colab_type": "code",
        "colab": {},
        "outputId": "5b0aa0a7-e6d1-422a-b386-8410526a2e3c"
      },
      "source": [
        "#Printing the shape of the bag of words model\n",
        "print(bow.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7551, 35189)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI_shxQlfEsb",
        "colab_type": "text"
      },
      "source": [
        "**2.2 Create TF-IDF Vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04_X_lIZfEsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fitting the bag of words data to the TF-IDF transformer\n",
        "tfidf_transformer = TfidfTransformer().fit(bow)\n",
        "\n",
        "# #Transforming the bag of words model to TF-IDF vectors\n",
        "storytfidf = tfidf_transformer.transform(bow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIfhnN_YfEsf",
        "colab_type": "text"
      },
      "source": [
        "### Training the classification models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGKfZFqpfEsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a Multinomial Naive Bayes Classifier and \n",
        "#Fitting the training data to the classifier\n",
        "classifier = MultinomialNB().fit(storytfidf, input_train_df['SECTION'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSE1nn2MfEsk",
        "colab_type": "text"
      },
      "source": [
        "### Predicting For The Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up2vjEgxfEsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_test_df = pd.read_excel('./sample_data/Data_Test.xlsx')\n",
        "final_test_df['CLEAN_STORY'] = final_test_df['STORY'].apply(text_cleaner)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOBBXHNrfEsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Exporting file to pickle to save time in processing data\n",
        "final_test_df.to_pickle('./sample_data/Pickles/final_test_df.pickle')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDerXvgLfEsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_test_df = pd.read_pickle('./sample_data/Pickles/final_test_df.pickle')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt1atoJsfEst",
        "colab_type": "code",
        "colab": {},
        "outputId": "55c2c8a0-dd3f-4896-b156-2495b765377c"
      },
      "source": [
        "#Printing the cleaned data\n",
        "print(final_test_df.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['2019 will see gadgets like gaming smartphones and wearable medical devices lifting the user experience to a whole new level\\n\\n\\nmint-india-wire consumer technologyconsumer technology trends in New Yeartech gadgetsFoldable phonesgaming smartphoneswearable medical devicestechnology\\n\\n\\nNew Delhi: Gadgets have become an integral part of our lives with most of us relying on some form of factor to communicate, commute, work, be informed or entertained. Year 2019 will see some gadgets lifting the user experience to a whole new level. Here’s what we can expect to see:\\n\\n\\nSmartphones with foldable screens: Foldable phones are finally moving from the concept stage to commercial launches. They are made up of organic light-emitting diode (OLED) panels with higher plastic substrates, allowing them to be bent without damage.\\n\\n\\nUS-based display maker Royole Corp’s foldable phone, FlexPai, has already arrived in select markets, while Samsung’s unnamed foldable phone is expected sometime next year. Samsung’s smartphone chief executive officer D.J. Koh has said they will make a million units of it. LG, too, is expected to display a foldable phone next year. Meanwhile Apple, Nokia, Lenovo and Huawei have also been working on foldable phones, reportedly.\\n\\n\\neSIM: Very soon your smartphone won’t need a physical SIM card anymore. The eSIM technology, already used by Apple in its iPhones and Apple Watch, replaces the physical SIM with a virtually embedded chip on the motherboard. eSIMs support multiple mobile operators and can be programmed to switch services.'\n",
            "  '2019 see gadgets like game smartphones wearable medical devices lift user experience whole new level mintindiawire consumer technologyconsumer technology trend New Yeartech gadgetsFoldable phonesgaming smartphoneswearable medical devicestechnology New Delhi Gadgets become integral part live us rely form factor communicate commute work inform entertain Year 2019 see gadgets lift user experience whole new level Heres expect see Smartphones foldable screen Foldable phone finally move concept stage commercial launch They make organic lightemitting diode OLED panel higher plastic substrates allow bend without damage USbased display maker Royole Corps foldable phone FlexPai already arrive select market Samsungs unnamed foldable phone expect sometime next year Samsungs smartphone chief executive officer DJ Koh say make million units LG expect display foldable phone next year Meanwhile Apple Nokia Lenovo Huawei also work foldable phone reportedly eSIM Very soon smartphone wont need physical SIM card anymore The eSIM technology already use Apple iPhones Apple Watch replace physical SIM virtually embed chip motherboard eSIMs support multiple mobile operators program switch service']\n",
            " ['It has also unleashed a wave of changes in the MCU that will make sure its future is a lot different than its past\\n\\n\\nKevin Feige had signalled diversity and more representation in the post-phase 3 MCU and Endgame does a lot to showcase the initiative'\n",
            "  'It also unleash wave change MCU make sure future lot different past Kevin Feige signal diversity representation postphase 3 MCU Endgame lot showcase initiative']\n",
            " ['It can be confusing to pick the right smartphone for yourself, so we have segregated the top smartphones under Rs 20,000 according to their strengths.\\n\\n\\nThe best smartphones under ₹20,000 categorised according to performance, camera, design and battery life\\n\\n\\nmint-india-wire phones under Rs 20000Poco F1Realme U1Redmi Note 6 Prorealme 2 proHonor PlayNokia 7.1Nova 3iAsus Zenfone Max Pro M1\\n\\n\\nGone are the days when you had to shell out big buck for buying smartphones with premium features. Technology has become more accessible recently and the biggest example of that lies in the sub-Rs 20,000 category—you get good performance, design and even software at a reasonable price.\\n\\n\\nIt can be confusing to pick the right smartphone for you, however, given the amount of variety that lies in the segment. So we have segregated the top smartphones under ₹ 20,000 according to their strengths, so you can pick the one that suits you best.\\n\\n\\nThis phone actually lies just north of the ₹ 20,000 price point. But if you have an HDFC debit or credit card, you can purchase the lowest spec variant with 6GB RAM and 64GB internal storage for as low as ₹ 19,999, making it the cheapest smartphone to run a Qualcomm Snapdragon 845 SoC. There’s not a lot to not like about this phone—it has the fastest processor Qualcomm has to offer, some thermal trickery to keep your smartphone cool during intense gaming sessions, a very good camera and some durable plastic that doesn’t shatter or pick up scratches.\\n\\n\\nIt even gets a modded version of the MIUI with an app drawer that allows you colour code your applications.'\n",
            "  'It confuse pick right smartphone segregate top smartphones Rs 20000 accord strengths The best smartphones ₹20000 categorise accord performance camera design battery life mintindiawire phone Rs 20000Poco F1Realme U1Redmi Note 6 Prorealme 2 proHonor PlayNokia 71Nova 3iAsus Zenfone Max Pro M1 Gone days shell big buck buy smartphones premium feature Technology become accessible recently biggest example lie subRs 20000 category—you get good performance design even software reasonable price It confuse pick right smartphone however give amount variety lie segment So segregate top smartphones ₹ 20000 accord strengths pick one suit best This phone actually lie north ₹ 20000 price point But HDFC debit credit card purchase lowest spec variant 6GB RAM 64GB internal storage low ₹ 19999 make cheapest smartphone run Qualcomm Snapdragon 845 SoC Theres lot like phone—it fastest processor Qualcomm offer thermal trickery keep smartphone cool intense game sessions good camera durable plastic doesnt shatter pick scratch It even get modded version MIUI app drawer allow colour code applications']\n",
            " ...\n",
            " ['On the photography front, the Note 5 Pro features a 12MP + 15MP dual rear camera setup, sporting an aperture of f/2.2, while on the front it has a 20MP selfie camera.\\n\\n\\nXiaomi Redmi Note 5 ProRedmi Note 5 Pro price cutRedmi Note 5 Pro price indiaRedmi Note 5 Pro specificationsRedmi Note 5 Pro saleRedmi Note 5 Pro units soldRedmi Note 5 Pro review'\n",
            "  'On photography front Note 5 Pro feature 12MP 15MP dual rear camera setup sport aperture f22 front 20MP selfie camera Xiaomi Redmi Note 5 ProRedmi Note 5 Pro price cutRedmi Note 5 Pro price indiaRedmi Note 5 Pro specificationsRedmi Note 5 Pro saleRedmi Note 5 Pro units soldRedmi Note 5 Pro review']\n",
            " ['UDAY mandated that discoms bring the gap between average revenue and average costs to zero. Here, too, there has been progress with the gap reducing (from ₹0.60/kWh in 2015-16 to ₹0.17/kWh in 2017-18), but 21 of 26 states are still unlikely to meet the target.\\n\\n\\nAccording to a National Institute of Public Finance and Policy study, this data suggests that the UDAY scheme is failing to turn around the power sector. The authors also find that discoms remain plagued by operational inefficiencies such as lack of effective billing procedures, poor measurement of power consumption, and ineffective monitoring of power theft.\\n\\n\\nTaken together, data shows that the NDA has built on the previous government’s work to get more households electrified—but quality of access still remains an issue.\\n\\n\\nWhile the government has tried to address this by improving the financial health of discoms, much more needs to be done. The inability of successive governments to revive discom fortunes could have important ramifications for India’s development.\\n\\n\\nThe World Bank estimates India’s electricity demand to treble by 2040. Addressing this rising demand will be critical for the development agenda of whichever party is elected to form the next government.'\n",
            "  'UDAY mandate discoms bring gap average revenue average cost zero Here progress gap reduce ₹060kWh 201516 ₹017kWh 201718 21 26 state still unlikely meet target According National Institute Public Finance Policy study data suggest UDAY scheme fail turn around power sector The author also find discoms remain plague operational inefficiencies lack effective bill procedures poor measurement power consumption ineffective monitor power theft Taken together data show NDA build previous governments work get households electrified—but quality access still remain issue While government try address improve financial health discoms much need do The inability successive governments revive discom fortunes could important ramifications Indias development The World Bank estimate Indias electricity demand treble 2040 Addressing rise demand critical development agenda whichever party elect form next government']\n",
            " ['Ripple also helps bank customers send money to people in many emerging markets including Mexico, India, and Thailand to increase their share of “this large and growing market\". What’s next? “Ripple is moving beyond blockchain, and connecting networks so that we can move money across networks. Again this is open-source and lightweight so it becomes easy to transfer money across networks. So we are building the ecosystem for networks to connect with each other and in our view globalization will be completed when data, goods and money flow seamlessly. That’s the way we think of it as an internet of value when the whole world gets connected through payment systems,\" Gupta said.'\n",
            "  'Ripple also help bank customers send money people many emerge market include Mexico India Thailand increase share “this large grow market Whats next “Ripple move beyond blockchain connect network move money across network Again opensource lightweight become easy transfer money across network So build ecosystem network connect view globalization complete data goods money flow seamlessly Thats way think internet value whole world get connect payment systems Gupta say']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgG9flvIfEsw",
        "colab_type": "text"
      },
      "source": [
        "### Create a pipeline to preprocess and initialize the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFotHqlTfEsx",
        "colab_type": "code",
        "colab": {},
        "outputId": "5d948480-4c3d-4825-ea83-44fcaba74dea"
      },
      "source": [
        "#Importing the Pipeline module from sklearn\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#Initializing the pipeline with necessary transformations and the required classifier\n",
        "pipe = Pipeline([\n",
        "('bow', CountVectorizer()),\n",
        "('tfidf', TfidfTransformer()),\n",
        "('classifier', MultinomialNB())])\n",
        "\n",
        "#Fitting the training data to the pipeline\n",
        "pipe.fit(input_train_df['CLEAN_STORY'], input_train_df['SECTION'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "     steps=[('bow', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "        strip_...f=False, use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qZerTasfEsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predicting the SECTION \n",
        "test_preds_mnb = pipe.predict(final_test_df['CLEAN_STORY'])\n",
        "\n",
        "# #Writing the predictions to an excel sheet\n",
        "output = pd.DataFrame(test_preds_mnb, columns = ['SECTION'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IHZm4j0fEs2",
        "colab_type": "code",
        "colab": {},
        "outputId": "b4bcf7ce-2ca9-4e69-990a-140d6cac53f8"
      },
      "source": [
        "final_test_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2748, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oPZ9MZ6fEs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output.to_excel(\"./Predictions/prediction3.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}